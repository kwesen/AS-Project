---
title: "AS Project"
author: "Wesenfeld Wo≈∫nica"
date: "2023-12-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data loading and imputation
We used kNN imputation with 18 neighbors.

The class distribution is extremely unbalanced, with 3 out of 4 classes having only about 22 instances each.

```{r loadimpute}
split_by_class <- function(df)
{
  temps <- list()
  for (cat in c(0, 1, 2, 3))
  {
    tdf <- df[df["Category"]==cat,]
    temps[[as.character(cat)]] <- tdf
  }
  return(temps)
}

hcv <- read.csv("data.csv")
hcv$Category <- as.factor(hcv$Category)
hcv$Sex <- as.factor(hcv$Sex)
hcv <- multiUS::KNNimp(hcv, k=18) # imputing using k-nearest neighbors

temps <- split_by_class(hcv)
```

# Boxplots for each class

```{r boxplots}
names = colnames(hcv)
names = names[-c(2,13)]
# 
# par(mfrow=c(3,4))
for (i in names)
{
  age = c(Group = c(0, 1, 2, 3) ,Age = c(unlist(temps[[1]][i]), 
                                         unlist(temps[[2]][i]), 
                                         unlist(temps[[3]][i]), 
                                         unlist(temps[[4]][i])))
  mat <-matrix(age, nrow = 4, byrow = T)
  diagnosis = c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
  # diagnosis = names(temps)
  boxplot(t(mat), names = diagnosis)
  title(i)
}
```

```{r countoutliers}
FindOutliers <- function(data) {
  lowerq = quantile(data)[2]
  upperq = quantile(data)[4]
  iqr = upperq - lowerq
  extreme.threshold.upper = (iqr * 1.5) + upperq
  extreme.threshold.lower = lowerq - (iqr * 1.5)
  result <- data > extreme.threshold.upper | data < extreme.threshold.lower
  return(sum(result))
}

out_count <- matrix(nrow = 4, ncol = 11)
colnames(out_count) <- colnames(hcv)[-c(2,13)]
rownames(out_count) <- names(temps)

for (cl in rownames(out_count))
{
  for (i in colnames(out_count))
  {
    out_count[cl, i] <- FindOutliers(unlist(temps[[cl]][i]))
  }
}
rownames(out_count) <- c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
out_count
```

```{r descriptives}
bdescriptives <- list()
for (cl in names(temps))
{
  bdescriptives[[cl]] <- summary(temps[[cl]][,-13])
}
bdescriptives$cat <- summary(hcv)
bdescriptives
```

# Q-Q plots
```{r qqplots}
for (cl in temps)
{
  par(mfrow=c(3,4))

  for (col in colnames(cl[,-c(2,13)]))
  {
    qqnorm(unlist(cl[col]), main = col)
  }
  mtext(switch(as.character(cl$Category[1]), '0' = "Blood Donor",
                  '1' = "Hepatitis",
                  '2' = "Fibrosis",
                  '3' = "Cirrhosis"), side = 3, line = -1.5, outer = T)
}
```

# Shapiro-Wilk tests
$H_0 \rightarrow$ sample belongs to the normal distribution

$H_a \rightarrow$ not $H_0$

```{r ben}
shapiros <- matrix(nrow = 11, ncol = 4)
colnames(shapiros) <- names(temps)
for (cl in temps)
{
  bens <- lapply(cl[,-c(2,13)], shapiro.test)
  
  shapiros[,cl$Category[1]] <- sapply(bens, "[[","p.value")
}
colnames(shapiros) <- c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
rownames(shapiros) <- colnames(hcv)[-c(2,13)]
shapiros.adjusted.bonf <- matrix(p.adjust(shapiros, method = "bonferroni"), nrow = nrow(shapiros), ncol = ncol(shapiros))
colnames(shapiros.adjusted.bonf) <- c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
rownames(shapiros.adjusted.bonf) <- colnames(hcv)[-c(2,13)]
shapiros.adjusted.bonf <- as.data.frame(shapiros.adjusted.bonf)

shapiros.adjusted.holm <- matrix(p.adjust(shapiros, method = "holm"), nrow = nrow(shapiros), ncol = ncol(shapiros))
colnames(shapiros.adjusted.holm) <- c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
rownames(shapiros.adjusted.holm) <- colnames(hcv)[-c(2,13)]
shapiros.adjusted.holm <- as.data.frame(shapiros.adjusted.holm)

shapiros <- as.data.frame(shapiros)
shapiros.adjusted.bonf
```

|      | Blood Donor  | Hepatitis    | Fibrosis     | Cirrhosis    |
|------|--------------|--------------|--------------|--------------|
|  Age | 1.312100e-08 | 7.125890e-01 | 0.9164536648 | 3.355084e-01 |
|  ALB | 2.899003e-14 | 6.398283e-01 | 0.3901453349 | 7.813236e-01 |
|  ALP | 2.691650e-07 | 4.685328e-04 | 0.1040438974 | 2.764596e-07 |
|  AST | 1.735090e-32 | 1.104465e-05 | 0.0285155286 | 4.567809e-04 |
|  BIL | 1.855860e-28 | 2.790052e-06 | 0.0258700855 | 2.868214e-06 |
|  CHE | 1.321403e-04 | 6.882919e-02 | 0.6766515214 | 3.111820e-03 |
| CHOL | 4.303689e-05 | 4.017470e-02 | 0.9328198708 | 3.973487e-01 |
| CREA | 7.923410e-05 | 3.295570e-04 | 0.0553331247 | 1.202464e-09 |
|  CGT | 2.102444e-30 | 1.234150e-06 | 0.0536414478 | 1.457298e-06 |
| PROT | 1.386594e-06 | 2.947508e-01 | 0.4215206563 | 3.672550e-01 |
|  ALT | 9.587215e-24 | 1.999425e-03 | 0.0005973611 | 1.773283e-07 |

Some samples from the Fibrosis class 

Since we have more than 2 groups, that do not belong to the normal distribution we will perform Kruskal-Wallis test
```{r}
shapiros.adjusted.holm
```

# Kruskal-Wallis

$H_0 \rightarrow$ mean ranks of the groups are the same

$H_a \rightarrow$ not $H_0$

```{r kruskal}
kruskal <- list()
for (cl in names(temps))
{
  kruskal[[cl]] <- kruskal.test(temps[[cl]][,-c(2,13)])
}

kruskal
```

We reject the null hypothesis, medians of the samples do not belong to the same distribution.

# PCA

```{r pca}
library(stats)
library(ggplot2)
library(ggfortify)

pca_set <- hcv
levels(pca_set$Category) <- c("Blood Donor", "Hepatitis", "Fibrosis", "Cirrhosis")
pca_set$Sex <- as.numeric(pca_set$Sex)

comps <- prcomp(pca_set[,-13], scale. = T)

autoplot(comps, data = pca_set, colour = "Category", loadings = F)
```

# Conover test
```{r}
library(conover.test)
con <- list()
for (cl in names(temps))
{
  con[[cl]] <- conover.test(temps[[cl]][,-c(2,13)])
}
```

```{r conover holm}
con.holm <- list()
for (cl in names(temps))
{
  con.holm[[cl]] <- conover.test(temps[[cl]][,-c(2,13)], method = "holm")
}
```

```{r conover bonferoni}

con.bonf <- list()
for (cl in names(temps))
{
  con.bonf[[cl]] <- conover.test(temps[[cl]][,-c(2,13)], method = "bonferroni")
}
```



Cirrhosis class can be partitioned from the Donors using the shown components with likely a decent accuracy. Fibrosis may be possible but hepatitis can be tough.


```{r extracting_conover_results}
extract <- function(string)
{
  match <- unlist(stringr::str_extract_all(string,"\\d+"))
}
make_matrix <- function(conover.result, matches)
{
  tmp_mat <- matrix(nrow = 10, ncol = 10)
  # tmp_mat[,] <- 0
  colnames(tmp_mat) <- as.character(1:10)
  rownames(tmp_mat) <- as.character(2:11)
  
  for (i in 1:dim(matches)[2])
  {
    col_id <- matches[1,i]
    row_id <- matches[2,i]
    tmp_mat[row_id, col_id] <- conover.result$P.adjusted[i]
  }
  return(as.data.frame(tmp_mat))
}

make_matrix.list <- function(conover.result.list)
{
  test.cases <- conover.result.list[["0"]]$comparisons
  matches <- sapply(test.cases, extract)
  conover_processed <- lapply(conover.result.list, make_matrix, matches)
  return(conover_processed)
}

conover_processed.holm <- make_matrix.list(con.holm)
conover_processed.bonf <- make_matrix.list(con.bonf)
conover_processed.none <- make_matrix.list(con)
```

```{r conover comparison}
conover.compare <- function(conover_processed, confidence = NULL)
{
  if (is.null(confidence)){confidence = 0.05/2}
  conover.comparison <- list()
  for (cl in names(conover_processed))
  {
    conover.comparison[[cl]] = conover_processed[[cl]] <= confidence
  }
  
  comparison_swap = conover.comparison[[1]]
  for (cl in names(conover_processed[-1]))
  {
    comparison_swap = conover.comparison[[cl]] & comparison_swap
  }
return(as.data.frame(comparison_swap))
}

conover.compared_bonf <- conover.compare(conover_processed.bonf)
conover.compared_holm <- conover.compare(conover_processed.holm)
conover.compared_none <- conover.compare(conover_processed.none)

rownames(conover.compared_bonf) <- names[-1]
colnames(conover.compared_bonf) <- names[-11]

rownames(conover.compared_holm) <- names[-1]
colnames(conover.compared_holm) <- names[-11]

rownames(conover.compared_none) <- names[-1]
colnames(conover.compared_none) <- names[-11]

```

```{r corelograms}
library(ggcorrplot)
library(gridExtra)
plots = list()

for (cl in names(temps))
{
  correl = round(cor(temps[[cl]][,-c(2,13)], method = "spearman"), 4)
  suppressWarnings({pcor = cor_pmat(temps[[cl]][,-c(2,13)], method = "spearman")})
  # plot(ggcorrplot(correl,  type = "lower", lab = F, title = diagnosis[as.numeric(cl)+1], p.mat = pcor)) # stupid but it wouldn't work otherwise | not longer needed but i will leave it as reminder of this stupid bugfix
  plots[[cl]] = ggcorrplot(correl,  type = "lower", lab = F, title = diagnosis[as.numeric(cl)+1], p.mat = pcor)
}
grid.arrange(grobs = plots, ncol = 2, nrow =2)
```

```{r conover_effect_size}
library(effsize)
cliff.delta.for_conover <- function(temp_mat){
  temp_mat <- temp_mat[sapply(temp_mat, is.numeric)] # remove non numeric columns
  max_iter <- ncol(temp_mat)-1
  temp_mat_out <- as.data.frame(matrix(nrow = max_iter, ncol = max_iter))
  
  row_names <- colnames(temp_mat)[-1]
  column_names <- colnames(temp_mat)[-11]
  
  rownames(temp_mat_out) <- row_names
  colnames(temp_mat_out) <- column_names
  
  # this caused warnings "The samples are fully disjoint, using approximate Confidence Interval estimation"
  # for some samples. Maybe it's a bad approach but makes it easier to look at
  suppressWarnings({ 
    for (i in 1:max_iter)
    {
      col_item_name <- column_names[i]
      for (j in i:max_iter)
      {
        row_item_name <- row_names[j]
        mag <- cliff.delta(temp_mat[,row_item_name], temp_mat[,col_item_name])$magnitude
        temp_mat_out[j,i] <- as.character(mag)
      }
    }
  })
  return(temp_mat_out)
}
conover.effect_size <- lapply(temps, cliff.delta.for_conover)
conover.effect_size
```


```{r}
groups <- list()
for (cl in names(temps))
{
  groups[[cl]] = temps[[cl]][sapply(temps[[cl]], is.numeric)]
}
eta.sqr = c()
for ( i in 1:ncol(groups[["0"]]))
{
  sums = c()
  counts = c()
  for(j in 1:length(groups))
  {
    sums = c(sums, sum(groups[[j]][,i]))
    counts = c(counts, nrow(groups[[j]]))
  }
  means = sums/counts
  mean.sqr = c()
  for(j in 1:length(groups))
  {
    mean.sqr = c(mean.sqr, sum((groups[[j]][,i]-means[j])**2))
  }
  mean.mean = sum(means)/length(groups)
  ss.among = c()
  for(j in 1:length(groups))
  {
    ss.among = c(ss.among, counts[j]*((means[j]-mean.mean))**2)
  }
  ss.among = sum(ss.among)
  ss.within = sum(mean.sqr)
  ss.total = ss.among + ss.within
  eta.sqr = c(eta.sqr, ss.among/ss.total)
}

names(eta.sqr) = colnames(groups[["1"]])

print(eta.sqr)
```


```{r}
eta.table <- data.frame(Effect_size = eta.sqr, Magnitude = character(length(eta.sqr)))

for (i in seq_along(eta.sqr))
{
  if (eta.sqr[i]<=0.01)
  {
    eta.table$Magnitude[i] <- "Negligible"
  }
  else if (eta.sqr[i]>0.01 && eta.sqr[i] <= 0.06){
    eta.table$Magnitude[i] <- "Small"
  }
  else if (eta.sqr[i]>0.06 && eta.sqr[i] <= 0.14){
    eta.table$Magnitude[i] <- "Medium"
  }
  else 
  {
    eta.table$Magnitude[i] <- "Large"
  }
}
```

```{r}
print(eta.table)
```

